
Linear Regression on Iris Dataset
In [1]:

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error

In [2]:

from sklearn.datasets import load_iris

In [3]:

iris = load_iris() #['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)'],

In [4]:

x = iris.data         # iris['data']
y = iris.target       # iris['target']

In [5]:

iris['target_names']

Out[5]:

array(['setosa', 'versicolor', 'virginica'], dtype='<U10')

In [6]:

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=0)

In [7]:

Lin = LinearRegression()

In [8]:

Lin.fit(x_train,y_train)

Out[8]:

LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)

In [9]:

Lin.coef_ # Here we find b1 of equation b0+b1*x

Out[9]:

array([-0.10627533, -0.0397204 ,  0.22894234,  0.61123074])

In [10]:

Lin.intercept_ # intercept (b0)

Out[10]:

0.16149541375178922

In [11]:

Pred_y = Lin.predict(x_test)

In [12]:

acc = r2_score(y_test,Pred_y)
acc

Out[12]:

0.9055032992676105

In [13]:

#MAE measures the average magnitude of the errors in a set of predictions,without considering their direction.
#The Mean Absolute Error(MAE) is the average of all absolute errors.
mean_absolute_error(y_test,Pred_y)

Out[13]:

0.18641707995607298

In [14]:

#RMSE is a quadratic scoring rule that also measures the average magnitude of the error.
# The average squared difference between the estimated values and the actual value
mean_squared_error(y_test,Pred_y)

Out[14]:

0.05092322206134319

